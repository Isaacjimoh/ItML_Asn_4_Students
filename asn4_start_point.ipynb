{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopy\n",
      "  Downloading geopy-2.3.0-py3-none-any.whl (119 kB)\n",
      "     -------------------------------------- 119.8/119.8 kB 2.3 MB/s eta 0:00:00\n",
      "Collecting geographiclib<3,>=1.52\n",
      "  Downloading geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "     ---------------------------------------- 40.3/40.3 kB 2.0 MB/s eta 0:00:00\n",
      "Installing collected packages: geographiclib, geopy\n",
      "Successfully installed geographiclib-2.0 geopy-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "  Downloading geopandas-0.12.2-py3-none-any.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 6.7 MB/s eta 0:00:00\n",
      "Collecting fiona>=1.8\n",
      "  Downloading Fiona-1.9.2-cp39-cp39-win_amd64.whl (22.0 MB)\n",
      "     --------------------------------------- 22.0/22.0 MB 16.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\lib\\site-packages (from geopandas) (21.3)\n",
      "Collecting pyproj>=2.6.1.post1\n",
      "  Downloading pyproj-3.5.0-cp39-cp39-win_amd64.whl (5.1 MB)\n",
      "     ---------------------------------------- 5.1/5.1 MB 27.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from geopandas) (1.4.4)\n",
      "Collecting shapely>=1.7\n",
      "  Downloading shapely-2.0.1-cp39-cp39-win_amd64.whl (1.4 MB)\n",
      "     ---------------------------------------- 1.4/1.4 MB 28.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click~=8.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from fiona>=1.8->geopandas) (8.0.4)\n",
      "Collecting cligj>=0.5\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp\\anaconda3\\lib\\site-packages (from fiona>=1.8->geopandas) (2022.9.14)\n",
      "Collecting click-plugins>=1.0\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from fiona>=1.8->geopandas) (21.4.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\hp\\anaconda3\\lib\\site-packages (from fiona>=1.8->geopandas) (4.11.3)\n",
      "Collecting munch>=2.3.2\n",
      "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->geopandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->geopandas) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging->geopandas) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click~=8.0->fiona>=1.8->geopandas) (0.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\hp\\anaconda3\\lib\\site-packages (from munch>=2.3.2->fiona>=1.8->geopandas) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from importlib-metadata->fiona>=1.8->geopandas) (3.8.0)\n",
      "Installing collected packages: shapely, pyproj, munch, cligj, click-plugins, fiona, geopandas\n",
      "Successfully installed click-plugins-1.1.1 cligj-0.7.2 fiona-1.9.2 geopandas-0.12.2 munch-2.5.0 pyproj-3.5.0 shapely-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.3.4-py3-none-any.whl (172 kB)\n",
      "     -------------------------------------- 172.2/172.2 kB 2.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\lib\\site-packages (from keras-tuner) (21.3)\n",
      "Collecting protobuf<=3.20.3\n",
      "  Downloading protobuf-3.20.3-cp39-cp39-win_amd64.whl (904 kB)\n",
      "     -------------------------------------- 904.2/904.2 kB 9.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from keras-tuner) (2.28.1)\n",
      "Requirement already satisfied: tensorflow>=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from keras-tuner) (2.12.0)\n",
      "Collecting kt-legacy\n",
      "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow>=2.0->keras-tuner) (2.12.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (0.4.6)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (2.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (2.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (1.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (0.2.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (0.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (4.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (63.4.1)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (1.16.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (1.6.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (0.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (3.7.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (1.51.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (16.0.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (23.3.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging->keras-tuner) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (0.37.1)\n",
      "Requirement already satisfied: scipy>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (1.9.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (2.0.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (0.7.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (2.16.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (3.3.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow>=2.0->keras-tuner) (3.2.2)\n",
      "Installing collected packages: kt-legacy, protobuf, keras-tuner\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.22.1\n",
      "    Uninstalling protobuf-4.22.1:\n",
      "      Successfully uninstalled protobuf-4.22.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\HP\\\\anaconda3\\\\Lib\\\\site-packages\\\\google\\\\~upb\\\\_message.cp39-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from geopy import distance\n",
    "import geopandas as gp\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - Simple Neural Networks\n",
    "\n",
    "For this assigment you'll do a realistic task - predicting fraud from transaction data. \n",
    "### Some Things to Note\n",
    "\n",
    "<ul>\n",
    "<li> The dataset is imbalanced. See: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data for some ideas\n",
    "<li> The locations, time, dob all likely aren't super useful on their own, but can be made into something more useful without much code or trouble. Think about how it may be useful to represent them. The data doesn't have missing rows, so this is the main data prep portion. \n",
    "<li> With respect to the above, and the other data here, we have a lot of rows of data. That means that we can generally handle data that is reasonably wide...\n",
    "</ul>\n",
    "\n",
    "### Deliverables\n",
    "\n",
    "Your final goal is to produce a function that can be called to classify a transaction:\n",
    "<ul>\n",
    "<li> Please submit two .ipynb files - one where you did your work, and another that can use your model to make predictions. \n",
    "<li> In that prediction file, please ensure:\n",
    "    <ul>\n",
    "    <li> You have a function where I can load a file, and the end result is a classificaiton matrix of your prediction accuracy. \n",
    "    <li> You load a trained model. There's no training here. \n",
    "    <li> Any data prep stuff that is needed for your data should be built in here. I'm going to run a test file that is the exact same setup as the training data.\n",
    "    <li> I should be able to open the prediction file, load the test data, and click RUN ALL and things should work. \n",
    "    <li> In addition to that, please include a short (~1-2 paragraph) description of what you did. Include anything that was innovative/different as well as a note on:\n",
    "        <ul>\n",
    "        <li> Any imbalanced data steps. \n",
    "        <li> Treatment of the location and time variables. What did you do to them?\n",
    "        <li> Model structure (layers/size)\n",
    "        <li> Any optimization steps included - regularization, dropouts, feature selection, etc...\n",
    "        </ul>\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "### Grades\n",
    "\n",
    "The grade breakdown is as follows:\n",
    "\n",
    "<ul>\n",
    "<li> Code preduces predictions - 40\n",
    "<li> Accuracy - 30\n",
    "<li> Explaination - 20\n",
    "<li> Balance/variable transformations - 10\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Banks</td>\n",
       "      <td>F</td>\n",
       "      <td>561 Perry Cove</td>\n",
       "      <td>Moravian Falls</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>Gill</td>\n",
       "      <td>F</td>\n",
       "      <td>43039 Riley Greens Suite 393</td>\n",
       "      <td>Orient</td>\n",
       "      <td>...</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>1978-06-21</td>\n",
       "      <td>1f76529f8574734946361c461b024d99</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>M</td>\n",
       "      <td>594 White Dale Suite 530</td>\n",
       "      <td>Malad City</td>\n",
       "      <td>...</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>1962-01-19</td>\n",
       "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>9443 Cynthia Court Apt. 038</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>...</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>1939</td>\n",
       "      <td>Patent attorney</td>\n",
       "      <td>1967-01-12</td>\n",
       "      <td>6b849c168bdad6f867558c3793159a81</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>375534208663984</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>M</td>\n",
       "      <td>408 Bradley Rest</td>\n",
       "      <td>Doe Hill</td>\n",
       "      <td>...</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>Dance movement psychotherapist</td>\n",
       "      <td>1986-03-28</td>\n",
       "      <td>a41d7549acf90789359a9aa5346dcb46</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  trans_date_trans_time            cc_num                            merchant  \\\n",
       "0   2019-01-01 00:00:18  2703186189652095          fraud_Rippin, Kub and Mann   \n",
       "1   2019-01-01 00:00:44      630423337322     fraud_Heller, Gutmann and Zieme   \n",
       "2   2019-01-01 00:00:51    38859492057661                fraud_Lind-Buckridge   \n",
       "3   2019-01-01 00:01:16  3534093764340240  fraud_Kutch, Hermiston and Farrell   \n",
       "4   2019-01-01 00:03:06   375534208663984                 fraud_Keeling-Crist   \n",
       "\n",
       "        category     amt      first     last gender  \\\n",
       "0       misc_net    4.97   Jennifer    Banks      F   \n",
       "1    grocery_pos  107.23  Stephanie     Gill      F   \n",
       "2  entertainment  220.11     Edward  Sanchez      M   \n",
       "3  gas_transport   45.00     Jeremy    White      M   \n",
       "4       misc_pos   41.96      Tyler   Garcia      M   \n",
       "\n",
       "                         street            city  ...      lat      long  \\\n",
       "0                561 Perry Cove  Moravian Falls  ...  36.0788  -81.1781   \n",
       "1  43039 Riley Greens Suite 393          Orient  ...  48.8878 -118.2105   \n",
       "2      594 White Dale Suite 530      Malad City  ...  42.1808 -112.2620   \n",
       "3   9443 Cynthia Court Apt. 038         Boulder  ...  46.2306 -112.1138   \n",
       "4              408 Bradley Rest        Doe Hill  ...  38.4207  -79.4629   \n",
       "\n",
       "   city_pop                                job         dob  \\\n",
       "0      3495          Psychologist, counselling  1988-03-09   \n",
       "1       149  Special educational needs teacher  1978-06-21   \n",
       "2      4154        Nature conservation officer  1962-01-19   \n",
       "3      1939                    Patent attorney  1967-01-12   \n",
       "4        99     Dance movement psychotherapist  1986-03-28   \n",
       "\n",
       "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
       "0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
       "1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
       "2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
       "3  6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
       "4  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
       "\n",
       "   is_fraud  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load some data\n",
    "df = pd.read_csv(\"https://jrssbcrsefilesnait.blob.core.windows.net/3950data1/fraudTrain.csv.zip\")\n",
    "df.drop(columns={\"Unnamed: 0\"}, inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <td>1296675</td>\n",
       "      <td>1274791</td>\n",
       "      <td>2019-04-22 16:02:01</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc_num</th>\n",
       "      <td>1296675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417192042079641088.0</td>\n",
       "      <td>1308806447000789248.0</td>\n",
       "      <td>60416207185.0</td>\n",
       "      <td>180042946491150.0</td>\n",
       "      <td>3521417320836166.0</td>\n",
       "      <td>4642255475285942.0</td>\n",
       "      <td>4992346398065154048.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant</th>\n",
       "      <td>1296675</td>\n",
       "      <td>693</td>\n",
       "      <td>fraud_Kilback LLC</td>\n",
       "      <td>4403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>1296675</td>\n",
       "      <td>14</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>131659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amt</th>\n",
       "      <td>1296675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.351035</td>\n",
       "      <td>160.316039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.65</td>\n",
       "      <td>47.52</td>\n",
       "      <td>83.14</td>\n",
       "      <td>28948.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>1296675</td>\n",
       "      <td>352</td>\n",
       "      <td>Christopher</td>\n",
       "      <td>26669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>1296675</td>\n",
       "      <td>481</td>\n",
       "      <td>Smith</td>\n",
       "      <td>28794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>1296675</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>709863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>street</th>\n",
       "      <td>1296675</td>\n",
       "      <td>983</td>\n",
       "      <td>0069 Robin Brooks Apt. 695</td>\n",
       "      <td>3123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>1296675</td>\n",
       "      <td>894</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>5617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>1296675</td>\n",
       "      <td>51</td>\n",
       "      <td>TX</td>\n",
       "      <td>94876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip</th>\n",
       "      <td>1296675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48800.671097</td>\n",
       "      <td>26893.222476</td>\n",
       "      <td>1257.0</td>\n",
       "      <td>26237.0</td>\n",
       "      <td>48174.0</td>\n",
       "      <td>72042.0</td>\n",
       "      <td>99783.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat</th>\n",
       "      <td>1296675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.537622</td>\n",
       "      <td>5.075808</td>\n",
       "      <td>20.0271</td>\n",
       "      <td>34.6205</td>\n",
       "      <td>39.3543</td>\n",
       "      <td>41.9404</td>\n",
       "      <td>66.6933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long</th>\n",
       "      <td>1296675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-90.226335</td>\n",
       "      <td>13.759077</td>\n",
       "      <td>-165.6723</td>\n",
       "      <td>-96.798</td>\n",
       "      <td>-87.4769</td>\n",
       "      <td>-80.158</td>\n",
       "      <td>-67.9503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_pop</th>\n",
       "      <td>1296675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88824.440563</td>\n",
       "      <td>301956.360689</td>\n",
       "      <td>23.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>2456.0</td>\n",
       "      <td>20328.0</td>\n",
       "      <td>2906700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job</th>\n",
       "      <td>1296675</td>\n",
       "      <td>494</td>\n",
       "      <td>Film/video editor</td>\n",
       "      <td>9779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dob</th>\n",
       "      <td>1296675</td>\n",
       "      <td>968</td>\n",
       "      <td>1977-03-23</td>\n",
       "      <td>5636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans_num</th>\n",
       "      <td>1296675</td>\n",
       "      <td>1296675</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unix_time</th>\n",
       "      <td>1296675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1349243636.726123</td>\n",
       "      <td>12841278.42336</td>\n",
       "      <td>1325376018.0</td>\n",
       "      <td>1338750742.5</td>\n",
       "      <td>1349249747.0</td>\n",
       "      <td>1359385375.5</td>\n",
       "      <td>1371816817.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merch_lat</th>\n",
       "      <td>1296675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.537338</td>\n",
       "      <td>5.109788</td>\n",
       "      <td>19.027785</td>\n",
       "      <td>34.733572</td>\n",
       "      <td>39.36568</td>\n",
       "      <td>41.957164</td>\n",
       "      <td>67.510267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merch_long</th>\n",
       "      <td>1296675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-90.226465</td>\n",
       "      <td>13.771091</td>\n",
       "      <td>-166.671242</td>\n",
       "      <td>-96.897276</td>\n",
       "      <td>-87.438392</td>\n",
       "      <td>-80.236796</td>\n",
       "      <td>-66.950902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_fraud</th>\n",
       "      <td>1296675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005789</td>\n",
       "      <td>0.075863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           count   unique                               top  \\\n",
       "trans_date_trans_time    1296675  1274791               2019-04-22 16:02:01   \n",
       "cc_num                 1296675.0      NaN                               NaN   \n",
       "merchant                 1296675      693                 fraud_Kilback LLC   \n",
       "category                 1296675       14                     gas_transport   \n",
       "amt                    1296675.0      NaN                               NaN   \n",
       "first                    1296675      352                       Christopher   \n",
       "last                     1296675      481                             Smith   \n",
       "gender                   1296675        2                                 F   \n",
       "street                   1296675      983        0069 Robin Brooks Apt. 695   \n",
       "city                     1296675      894                        Birmingham   \n",
       "state                    1296675       51                                TX   \n",
       "zip                    1296675.0      NaN                               NaN   \n",
       "lat                    1296675.0      NaN                               NaN   \n",
       "long                   1296675.0      NaN                               NaN   \n",
       "city_pop               1296675.0      NaN                               NaN   \n",
       "job                      1296675      494                 Film/video editor   \n",
       "dob                      1296675      968                        1977-03-23   \n",
       "trans_num                1296675  1296675  0b242abb623afc578575680df30655b9   \n",
       "unix_time              1296675.0      NaN                               NaN   \n",
       "merch_lat              1296675.0      NaN                               NaN   \n",
       "merch_long             1296675.0      NaN                               NaN   \n",
       "is_fraud               1296675.0      NaN                               NaN   \n",
       "\n",
       "                         freq                  mean                    std  \\\n",
       "trans_date_trans_time       4                   NaN                    NaN   \n",
       "cc_num                    NaN  417192042079641088.0  1308806447000789248.0   \n",
       "merchant                 4403                   NaN                    NaN   \n",
       "category               131659                   NaN                    NaN   \n",
       "amt                       NaN             70.351035             160.316039   \n",
       "first                   26669                   NaN                    NaN   \n",
       "last                    28794                   NaN                    NaN   \n",
       "gender                 709863                   NaN                    NaN   \n",
       "street                   3123                   NaN                    NaN   \n",
       "city                     5617                   NaN                    NaN   \n",
       "state                   94876                   NaN                    NaN   \n",
       "zip                       NaN          48800.671097           26893.222476   \n",
       "lat                       NaN             38.537622               5.075808   \n",
       "long                      NaN            -90.226335              13.759077   \n",
       "city_pop                  NaN          88824.440563          301956.360689   \n",
       "job                      9779                   NaN                    NaN   \n",
       "dob                      5636                   NaN                    NaN   \n",
       "trans_num                   1                   NaN                    NaN   \n",
       "unix_time                 NaN     1349243636.726123         12841278.42336   \n",
       "merch_lat                 NaN             38.537338               5.109788   \n",
       "merch_long                NaN            -90.226465              13.771091   \n",
       "is_fraud                  NaN              0.005789               0.075863   \n",
       "\n",
       "                                 min                25%                 50%  \\\n",
       "trans_date_trans_time            NaN                NaN                 NaN   \n",
       "cc_num                 60416207185.0  180042946491150.0  3521417320836166.0   \n",
       "merchant                         NaN                NaN                 NaN   \n",
       "category                         NaN                NaN                 NaN   \n",
       "amt                              1.0               9.65               47.52   \n",
       "first                            NaN                NaN                 NaN   \n",
       "last                             NaN                NaN                 NaN   \n",
       "gender                           NaN                NaN                 NaN   \n",
       "street                           NaN                NaN                 NaN   \n",
       "city                             NaN                NaN                 NaN   \n",
       "state                            NaN                NaN                 NaN   \n",
       "zip                           1257.0            26237.0             48174.0   \n",
       "lat                          20.0271            34.6205             39.3543   \n",
       "long                       -165.6723            -96.798            -87.4769   \n",
       "city_pop                        23.0              743.0              2456.0   \n",
       "job                              NaN                NaN                 NaN   \n",
       "dob                              NaN                NaN                 NaN   \n",
       "trans_num                        NaN                NaN                 NaN   \n",
       "unix_time               1325376018.0       1338750742.5        1349249747.0   \n",
       "merch_lat                  19.027785          34.733572            39.36568   \n",
       "merch_long               -166.671242         -96.897276          -87.438392   \n",
       "is_fraud                         0.0                0.0                 0.0   \n",
       "\n",
       "                                      75%                    max  \n",
       "trans_date_trans_time                 NaN                    NaN  \n",
       "cc_num                 4642255475285942.0  4992346398065154048.0  \n",
       "merchant                              NaN                    NaN  \n",
       "category                              NaN                    NaN  \n",
       "amt                                 83.14                28948.9  \n",
       "first                                 NaN                    NaN  \n",
       "last                                  NaN                    NaN  \n",
       "gender                                NaN                    NaN  \n",
       "street                                NaN                    NaN  \n",
       "city                                  NaN                    NaN  \n",
       "state                                 NaN                    NaN  \n",
       "zip                               72042.0                99783.0  \n",
       "lat                               41.9404                66.6933  \n",
       "long                              -80.158               -67.9503  \n",
       "city_pop                          20328.0              2906700.0  \n",
       "job                                   NaN                    NaN  \n",
       "dob                                   NaN                    NaN  \n",
       "trans_num                             NaN                    NaN  \n",
       "unix_time                    1359385375.5           1371816817.0  \n",
       "merch_lat                       41.957164              67.510267  \n",
       "merch_long                     -80.236796             -66.950902  \n",
       "is_fraud                              0.0                    1.0  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"all\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 22 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   trans_date_trans_time  1296675 non-null  object \n",
      " 1   cc_num                 1296675 non-null  int64  \n",
      " 2   merchant               1296675 non-null  object \n",
      " 3   category               1296675 non-null  object \n",
      " 4   amt                    1296675 non-null  float64\n",
      " 5   first                  1296675 non-null  object \n",
      " 6   last                   1296675 non-null  object \n",
      " 7   gender                 1296675 non-null  object \n",
      " 8   street                 1296675 non-null  object \n",
      " 9   city                   1296675 non-null  object \n",
      " 10  state                  1296675 non-null  object \n",
      " 11  zip                    1296675 non-null  int64  \n",
      " 12  lat                    1296675 non-null  float64\n",
      " 13  long                   1296675 non-null  float64\n",
      " 14  city_pop               1296675 non-null  int64  \n",
      " 15  job                    1296675 non-null  object \n",
      " 16  dob                    1296675 non-null  object \n",
      " 17  trans_num              1296675 non-null  object \n",
      " 18  unix_time              1296675 non-null  int64  \n",
      " 19  merch_lat              1296675 non-null  float64\n",
      " 20  merch_long             1296675 non-null  float64\n",
      " 21  is_fraud               1296675 non-null  int64  \n",
      "dtypes: float64(5), int64(5), object(12)\n",
      "memory usage: 217.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Lat/Lon\n",
    "\n",
    "We can utilize lat/lon of the home and merchant in a useful way?\n",
    "\n",
    "Note: I left the section headers in from when I did it. You can remove them if you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To utilize the latitude and longitude of the home and merchant, we can calculate the distance between them using the geopy package. \n",
    "#This can provide useful information about the geographical relationship between the transaction and the cardholder's location. \n",
    "#We can create a new feature \"distance\" which represents the distance between the home and merchant locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "latlong = gp.GeoDataFrame(df[['lat','long']], geometry=gp.points_from_xy(df['lat'], df['long']))\n",
    "merchlatlong = gp.GeoDataFrame(df[['merch_lat','merch_long']], geometry=gp.points_from_xy(df['merch_lat'], df['merch_long']))\n",
    "df['distance'] = latlong['geometry'].distance(merchlatlong['geometry'],align=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Time\n",
    "\n",
    "Can we make date/time and the date of birth into something useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The \"trans_date_trans_time\" column contains both the transaction date and time. \n",
    "#Splitted the column into two separate columns, one for the date and one for the time.\n",
    "#We can also extract additional features from the transaction date and time, such as the day of the week, the hour of the day, and whether it is a weekend or not. \n",
    "#helpful in identifying any patterns related to specific days or times.\n",
    "#Convert the 'dob' column to datetime format using the 'pd.to_datetime()' method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with Time\n",
    "df['trans_date_trans_time'] = df['trans_date_trans_time'].apply(lambda x: dt.datetime.fromisoformat(str(x)))\n",
    "df['dob'] = df['dob'].apply(lambda x: dt.datetime.fromisoformat(str(x)))\n",
    "df['age'] = df['trans_date_trans_time'] - df['dob']\n",
    "\n",
    "df['age'] = df['age'].apply(lambda x: x.days//365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Target Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview:\n",
      "    Total: 1296675\n",
      "    Positive: 7506 (0.58% of total)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check target balance\n",
    "neg, pos = np.bincount(df['is_fraud'])\n",
    "total = neg + pos\n",
    "print('Overview:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))\n",
    "\n",
    "sns.countplot(df['is_fraud'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counted the number of occurrences of each class in the is_fraud column\n",
    "#printed the counts and proportion of the two classes.\n",
    "#generated a countplot of the is_fraud column\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "# Split data into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df.drop(columns=['trans_date_trans_time', 'gender', 'merchant', 'first', 'last', 'street', 'city', 'state', 'zip',\n",
    "                  'job', 'dob', 'trans_num'], inplace=True)\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 24 columns):\n",
      " #   Column                   Non-Null Count    Dtype  \n",
      "---  ------                   --------------    -----  \n",
      " 0   cc_num                   1296675 non-null  int64  \n",
      " 1   amt                      1296675 non-null  float64\n",
      " 2   lat                      1296675 non-null  float64\n",
      " 3   long                     1296675 non-null  float64\n",
      " 4   city_pop                 1296675 non-null  int64  \n",
      " 5   unix_time                1296675 non-null  int64  \n",
      " 6   merch_lat                1296675 non-null  float64\n",
      " 7   merch_long               1296675 non-null  float64\n",
      " 8   is_fraud                 1296675 non-null  int64  \n",
      " 9   distance                 1296675 non-null  float64\n",
      " 10  age                      1296675 non-null  int64  \n",
      " 11  category_food_dining     1296675 non-null  uint8  \n",
      " 12  category_gas_transport   1296675 non-null  uint8  \n",
      " 13  category_grocery_net     1296675 non-null  uint8  \n",
      " 14  category_grocery_pos     1296675 non-null  uint8  \n",
      " 15  category_health_fitness  1296675 non-null  uint8  \n",
      " 16  category_home            1296675 non-null  uint8  \n",
      " 17  category_kids_pets       1296675 non-null  uint8  \n",
      " 18  category_misc_net        1296675 non-null  uint8  \n",
      " 19  category_misc_pos        1296675 non-null  uint8  \n",
      " 20  category_personal_care   1296675 non-null  uint8  \n",
      " 21  category_shopping_net    1296675 non-null  uint8  \n",
      " 22  category_shopping_pos    1296675 non-null  uint8  \n",
      " 23  category_travel          1296675 non-null  uint8  \n",
      "dtypes: float64(6), int64(5), uint8(13)\n",
      "memory usage: 124.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a utility from sklearn to split and shuffle your dataset.\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form np arrays of labels and features.\n",
    "train_labels = np.array(train_df.pop('is_fraud'))\n",
    "bool_train_labels = train_labels != 0\n",
    "val_labels = np.array(val_df.pop('is_fraud'))\n",
    "test_labels = np.array(test_df.pop('is_fraud'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.array(train_df)\n",
    "val_features = np.array(val_df)\n",
    "test_features = np.array(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "train_features = scale.fit_transform(train_features)\n",
    "val_features = scale.fit_transform(val_features)\n",
    "test_features = scale.fit_transform(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "def make_model(metrics=METRICS, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(72, activation='relu',input_shape=(train_features.shape[-1],)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(36, activation='relu'),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(1, activation='sigmoid',bias_initializer=output_bias)\n",
    "  ])\n",
    "\n",
    "    model.compile(\n",
    "      optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
    "  print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "  print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
    "  print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
    "  print('Total Fraudulent Transactions: ', np.sum(cm[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 72)                1728      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 72)                0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 36)                2628      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 36)                0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 37        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,393\n",
      "Trainable params: 4,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_prc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "model = make_model(metrics=METRICS)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 1.01\n",
      "Weight for class 1: 101.62\n"
     ]
    }
   ],
   "source": [
    "weight_for_0 = (1 / target_count[0]) * (target_count.sum() / 1.0)\n",
    "weight_for_1 = (1 / target_count[1]) * (target_count.sum() / 1.7)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "406/406 [==============================] - 5s 8ms/step - loss: 0.0571 - tp: 238.0000 - fp: 9575.0000 - tn: 815525.0000 - fn: 4534.0000 - accuracy: 0.9830 - precision: 0.0243 - recall: 0.0499 - auc: 0.7554 - prc: 0.0204 - val_loss: 0.0246 - val_tp: 84.0000 - val_fp: 46.0000 - val_tn: 206166.0000 - val_fn: 1172.0000 - val_accuracy: 0.9941 - val_precision: 0.6462 - val_recall: 0.0669 - val_auc: 0.8474 - val_prc: 0.3234\n",
      "Epoch 2/100\n",
      "406/406 [==============================] - 2s 6ms/step - loss: 0.0233 - tp: 606.0000 - fp: 473.0000 - tn: 824627.0000 - fn: 4166.0000 - accuracy: 0.9944 - precision: 0.5616 - recall: 0.1270 - auc: 0.8563 - prc: 0.3205 - val_loss: 0.0215 - val_tp: 209.0000 - val_fp: 102.0000 - val_tn: 206110.0000 - val_fn: 1047.0000 - val_accuracy: 0.9945 - val_precision: 0.6720 - val_recall: 0.1664 - val_auc: 0.8600 - val_prc: 0.4217\n",
      "Epoch 3/100\n",
      "406/406 [==============================] - 2s 6ms/step - loss: 0.0206 - tp: 960.0000 - fp: 598.0000 - tn: 824502.0000 - fn: 3812.0000 - accuracy: 0.9947 - precision: 0.6162 - recall: 0.2012 - auc: 0.8690 - prc: 0.4063 - val_loss: 0.0192 - val_tp: 296.0000 - val_fp: 120.0000 - val_tn: 206092.0000 - val_fn: 960.0000 - val_accuracy: 0.9948 - val_precision: 0.7115 - val_recall: 0.2357 - val_auc: 0.8696 - val_prc: 0.4924\n",
      "Epoch 4/100\n",
      "406/406 [==============================] - 2s 6ms/step - loss: 0.0186 - tp: 1600.0000 - fp: 686.0000 - tn: 824414.0000 - fn: 3172.0000 - accuracy: 0.9954 - precision: 0.6999 - recall: 0.3353 - auc: 0.8801 - prc: 0.4951 - val_loss: 0.0178 - val_tp: 450.0000 - val_fp: 138.0000 - val_tn: 206074.0000 - val_fn: 806.0000 - val_accuracy: 0.9954 - val_precision: 0.7653 - val_recall: 0.3583 - val_auc: 0.8728 - val_prc: 0.5636\n",
      "Epoch 5/100\n",
      "406/406 [==============================] - 2s 6ms/step - loss: 0.0174 - tp: 2091.0000 - fp: 703.0000 - tn: 824397.0000 - fn: 2681.0000 - accuracy: 0.9959 - precision: 0.7484 - recall: 0.4382 - auc: 0.8812 - prc: 0.5623 - val_loss: 0.0164 - val_tp: 569.0000 - val_fp: 123.0000 - val_tn: 206089.0000 - val_fn: 687.0000 - val_accuracy: 0.9961 - val_precision: 0.8223 - val_recall: 0.4530 - val_auc: 0.8730 - val_prc: 0.6284\n",
      "Epoch 6/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0165 - tp: 2326.0000 - fp: 709.0000 - tn: 824391.0000 - fn: 2446.0000 - accuracy: 0.9962 - precision: 0.7664 - recall: 0.4874 - auc: 0.8854 - prc: 0.6057 - val_loss: 0.0159 - val_tp: 612.0000 - val_fp: 131.0000 - val_tn: 206081.0000 - val_fn: 644.0000 - val_accuracy: 0.9963 - val_precision: 0.8237 - val_recall: 0.4873 - val_auc: 0.8757 - val_prc: 0.6425\n",
      "Epoch 7/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0159 - tp: 2451.0000 - fp: 719.0000 - tn: 824381.0000 - fn: 2321.0000 - accuracy: 0.9963 - precision: 0.7732 - recall: 0.5136 - auc: 0.8881 - prc: 0.6229 - val_loss: 0.0154 - val_tp: 640.0000 - val_fp: 146.0000 - val_tn: 206066.0000 - val_fn: 616.0000 - val_accuracy: 0.9963 - val_precision: 0.8142 - val_recall: 0.5096 - val_auc: 0.8786 - val_prc: 0.6508\n",
      "Epoch 8/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0156 - tp: 2510.0000 - fp: 703.0000 - tn: 824397.0000 - fn: 2262.0000 - accuracy: 0.9964 - precision: 0.7812 - recall: 0.5260 - auc: 0.8887 - prc: 0.6315 - val_loss: 0.0151 - val_tp: 657.0000 - val_fp: 144.0000 - val_tn: 206068.0000 - val_fn: 599.0000 - val_accuracy: 0.9964 - val_precision: 0.8202 - val_recall: 0.5231 - val_auc: 0.8864 - val_prc: 0.6591\n",
      "Epoch 9/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0152 - tp: 2571.0000 - fp: 710.0000 - tn: 824390.0000 - fn: 2201.0000 - accuracy: 0.9965 - precision: 0.7836 - recall: 0.5388 - auc: 0.8940 - prc: 0.6409 - val_loss: 0.0150 - val_tp: 631.0000 - val_fp: 134.0000 - val_tn: 206078.0000 - val_fn: 625.0000 - val_accuracy: 0.9963 - val_precision: 0.8248 - val_recall: 0.5024 - val_auc: 0.8945 - val_prc: 0.6619\n",
      "Epoch 10/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0150 - tp: 2621.0000 - fp: 688.0000 - tn: 824412.0000 - fn: 2151.0000 - accuracy: 0.9966 - precision: 0.7921 - recall: 0.5492 - auc: 0.8987 - prc: 0.6451 - val_loss: 0.0146 - val_tp: 646.0000 - val_fp: 133.0000 - val_tn: 206079.0000 - val_fn: 610.0000 - val_accuracy: 0.9964 - val_precision: 0.8293 - val_recall: 0.5143 - val_auc: 0.9065 - val_prc: 0.6686\n",
      "Epoch 11/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0147 - tp: 2610.0000 - fp: 690.0000 - tn: 824410.0000 - fn: 2162.0000 - accuracy: 0.9966 - precision: 0.7909 - recall: 0.5469 - auc: 0.9032 - prc: 0.6510 - val_loss: 0.0148 - val_tp: 619.0000 - val_fp: 119.0000 - val_tn: 206093.0000 - val_fn: 637.0000 - val_accuracy: 0.9964 - val_precision: 0.8388 - val_recall: 0.4928 - val_auc: 0.8822 - val_prc: 0.6616\n",
      "Epoch 12/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0145 - tp: 2597.0000 - fp: 700.0000 - tn: 824400.0000 - fn: 2175.0000 - accuracy: 0.9965 - precision: 0.7877 - recall: 0.5442 - auc: 0.9059 - prc: 0.6526 - val_loss: 0.0143 - val_tp: 642.0000 - val_fp: 136.0000 - val_tn: 206076.0000 - val_fn: 614.0000 - val_accuracy: 0.9964 - val_precision: 0.8252 - val_recall: 0.5111 - val_auc: 0.9010 - val_prc: 0.6743\n",
      "Epoch 13/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0142 - tp: 2637.0000 - fp: 705.0000 - tn: 824395.0000 - fn: 2135.0000 - accuracy: 0.9966 - precision: 0.7890 - recall: 0.5526 - auc: 0.9131 - prc: 0.6562 - val_loss: 0.0138 - val_tp: 694.0000 - val_fp: 155.0000 - val_tn: 206057.0000 - val_fn: 562.0000 - val_accuracy: 0.9965 - val_precision: 0.8174 - val_recall: 0.5525 - val_auc: 0.9220 - val_prc: 0.6877\n",
      "Epoch 14/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0140 - tp: 2668.0000 - fp: 698.0000 - tn: 824402.0000 - fn: 2104.0000 - accuracy: 0.9966 - precision: 0.7926 - recall: 0.5591 - auc: 0.9174 - prc: 0.6645 - val_loss: 0.0134 - val_tp: 687.0000 - val_fp: 147.0000 - val_tn: 206065.0000 - val_fn: 569.0000 - val_accuracy: 0.9965 - val_precision: 0.8237 - val_recall: 0.5470 - val_auc: 0.9241 - val_prc: 0.7065\n",
      "Epoch 15/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0135 - tp: 2702.0000 - fp: 723.0000 - tn: 824377.0000 - fn: 2070.0000 - accuracy: 0.9966 - precision: 0.7889 - recall: 0.5662 - auc: 0.9243 - prc: 0.6774 - val_loss: 0.0130 - val_tp: 643.0000 - val_fp: 122.0000 - val_tn: 206090.0000 - val_fn: 613.0000 - val_accuracy: 0.9965 - val_precision: 0.8405 - val_recall: 0.5119 - val_auc: 0.9242 - val_prc: 0.7166\n",
      "Epoch 16/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0129 - tp: 2713.0000 - fp: 713.0000 - tn: 824387.0000 - fn: 2059.0000 - accuracy: 0.9967 - precision: 0.7919 - recall: 0.5685 - auc: 0.9307 - prc: 0.6921 - val_loss: 0.0129 - val_tp: 677.0000 - val_fp: 146.0000 - val_tn: 206066.0000 - val_fn: 579.0000 - val_accuracy: 0.9965 - val_precision: 0.8226 - val_recall: 0.5390 - val_auc: 0.9246 - val_prc: 0.7166\n",
      "Epoch 17/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0125 - tp: 2754.0000 - fp: 742.0000 - tn: 824358.0000 - fn: 2018.0000 - accuracy: 0.9967 - precision: 0.7878 - recall: 0.5771 - auc: 0.9337 - prc: 0.7036 - val_loss: 0.0120 - val_tp: 662.0000 - val_fp: 124.0000 - val_tn: 206088.0000 - val_fn: 594.0000 - val_accuracy: 0.9965 - val_precision: 0.8422 - val_recall: 0.5271 - val_auc: 0.9341 - val_prc: 0.7384\n",
      "Epoch 18/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0121 - tp: 2839.0000 - fp: 718.0000 - tn: 824382.0000 - fn: 1933.0000 - accuracy: 0.9968 - precision: 0.7981 - recall: 0.5949 - auc: 0.9374 - prc: 0.7134 - val_loss: 0.0115 - val_tp: 712.0000 - val_fp: 152.0000 - val_tn: 206060.0000 - val_fn: 544.0000 - val_accuracy: 0.9966 - val_precision: 0.8241 - val_recall: 0.5669 - val_auc: 0.9442 - val_prc: 0.7388\n",
      "Epoch 19/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0117 - tp: 2842.0000 - fp: 725.0000 - tn: 824375.0000 - fn: 1930.0000 - accuracy: 0.9968 - precision: 0.7967 - recall: 0.5956 - auc: 0.9396 - prc: 0.7217 - val_loss: 0.0112 - val_tp: 777.0000 - val_fp: 162.0000 - val_tn: 206050.0000 - val_fn: 479.0000 - val_accuracy: 0.9969 - val_precision: 0.8275 - val_recall: 0.6186 - val_auc: 0.9432 - val_prc: 0.7491\n",
      "Epoch 20/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0116 - tp: 2969.0000 - fp: 766.0000 - tn: 824334.0000 - fn: 1803.0000 - accuracy: 0.9969 - precision: 0.7949 - recall: 0.6222 - auc: 0.9401 - prc: 0.7273 - val_loss: 0.0110 - val_tp: 737.0000 - val_fp: 153.0000 - val_tn: 206059.0000 - val_fn: 519.0000 - val_accuracy: 0.9968 - val_precision: 0.8281 - val_recall: 0.5868 - val_auc: 0.9409 - val_prc: 0.7537\n",
      "Epoch 21/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0113 - tp: 2962.0000 - fp: 785.0000 - tn: 824315.0000 - fn: 1810.0000 - accuracy: 0.9969 - precision: 0.7905 - recall: 0.6207 - auc: 0.9443 - prc: 0.7341 - val_loss: 0.0112 - val_tp: 708.0000 - val_fp: 116.0000 - val_tn: 206096.0000 - val_fn: 548.0000 - val_accuracy: 0.9968 - val_precision: 0.8592 - val_recall: 0.5637 - val_auc: 0.9305 - val_prc: 0.7553\n",
      "Epoch 22/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0112 - tp: 2975.0000 - fp: 783.0000 - tn: 824317.0000 - fn: 1797.0000 - accuracy: 0.9969 - precision: 0.7916 - recall: 0.6234 - auc: 0.9424 - prc: 0.7356 - val_loss: 0.0110 - val_tp: 705.0000 - val_fp: 136.0000 - val_tn: 206076.0000 - val_fn: 551.0000 - val_accuracy: 0.9967 - val_precision: 0.8383 - val_recall: 0.5613 - val_auc: 0.9351 - val_prc: 0.7528\n",
      "Epoch 23/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0110 - tp: 2990.0000 - fp: 779.0000 - tn: 824321.0000 - fn: 1782.0000 - accuracy: 0.9969 - precision: 0.7933 - recall: 0.6266 - auc: 0.9478 - prc: 0.7411 - val_loss: 0.0106 - val_tp: 758.0000 - val_fp: 137.0000 - val_tn: 206075.0000 - val_fn: 498.0000 - val_accuracy: 0.9969 - val_precision: 0.8469 - val_recall: 0.6035 - val_auc: 0.9602 - val_prc: 0.7714\n",
      "Epoch 24/100\n",
      "406/406 [==============================] - 4s 10ms/step - loss: 0.0109 - tp: 2991.0000 - fp: 768.0000 - tn: 824332.0000 - fn: 1781.0000 - accuracy: 0.9969 - precision: 0.7957 - recall: 0.6268 - auc: 0.9475 - prc: 0.7450 - val_loss: 0.0106 - val_tp: 774.0000 - val_fp: 140.0000 - val_tn: 206072.0000 - val_fn: 482.0000 - val_accuracy: 0.9970 - val_precision: 0.8468 - val_recall: 0.6162 - val_auc: 0.9479 - val_prc: 0.7668\n",
      "Epoch 25/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0108 - tp: 2959.0000 - fp: 722.0000 - tn: 824378.0000 - fn: 1813.0000 - accuracy: 0.9969 - precision: 0.8039 - recall: 0.6201 - auc: 0.9500 - prc: 0.7448 - val_loss: 0.0105 - val_tp: 799.0000 - val_fp: 151.0000 - val_tn: 206061.0000 - val_fn: 457.0000 - val_accuracy: 0.9971 - val_precision: 0.8411 - val_recall: 0.6361 - val_auc: 0.9533 - val_prc: 0.7685\n",
      "Epoch 26/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0107 - tp: 2981.0000 - fp: 743.0000 - tn: 824357.0000 - fn: 1791.0000 - accuracy: 0.9969 - precision: 0.8005 - recall: 0.6247 - auc: 0.9505 - prc: 0.7487 - val_loss: 0.0105 - val_tp: 853.0000 - val_fp: 201.0000 - val_tn: 206011.0000 - val_fn: 403.0000 - val_accuracy: 0.9971 - val_precision: 0.8093 - val_recall: 0.6791 - val_auc: 0.9550 - val_prc: 0.7687\n",
      "Epoch 27/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0106 - tp: 3034.0000 - fp: 773.0000 - tn: 824327.0000 - fn: 1738.0000 - accuracy: 0.9970 - precision: 0.7970 - recall: 0.6358 - auc: 0.9531 - prc: 0.7488 - val_loss: 0.0104 - val_tp: 780.0000 - val_fp: 143.0000 - val_tn: 206069.0000 - val_fn: 476.0000 - val_accuracy: 0.9970 - val_precision: 0.8451 - val_recall: 0.6210 - val_auc: 0.9571 - val_prc: 0.7749\n",
      "Epoch 28/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0106 - tp: 3024.0000 - fp: 741.0000 - tn: 824359.0000 - fn: 1748.0000 - accuracy: 0.9970 - precision: 0.8032 - recall: 0.6337 - auc: 0.9512 - prc: 0.7501 - val_loss: 0.0108 - val_tp: 749.0000 - val_fp: 129.0000 - val_tn: 206083.0000 - val_fn: 507.0000 - val_accuracy: 0.9969 - val_precision: 0.8531 - val_recall: 0.5963 - val_auc: 0.9350 - val_prc: 0.7694\n",
      "Epoch 29/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0104 - tp: 3027.0000 - fp: 732.0000 - tn: 824368.0000 - fn: 1745.0000 - accuracy: 0.9970 - precision: 0.8053 - recall: 0.6343 - auc: 0.9517 - prc: 0.7568 - val_loss: 0.0103 - val_tp: 790.0000 - val_fp: 139.0000 - val_tn: 206073.0000 - val_fn: 466.0000 - val_accuracy: 0.9971 - val_precision: 0.8504 - val_recall: 0.6290 - val_auc: 0.9727 - val_prc: 0.7800\n",
      "Epoch 30/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0104 - tp: 3048.0000 - fp: 748.0000 - tn: 824352.0000 - fn: 1724.0000 - accuracy: 0.9970 - precision: 0.8030 - recall: 0.6387 - auc: 0.9541 - prc: 0.7577 - val_loss: 0.0105 - val_tp: 781.0000 - val_fp: 142.0000 - val_tn: 206070.0000 - val_fn: 475.0000 - val_accuracy: 0.9970 - val_precision: 0.8462 - val_recall: 0.6218 - val_auc: 0.9423 - val_prc: 0.7738\n",
      "Epoch 31/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0104 - tp: 3037.0000 - fp: 726.0000 - tn: 824374.0000 - fn: 1735.0000 - accuracy: 0.9970 - precision: 0.8071 - recall: 0.6364 - auc: 0.9553 - prc: 0.7581 - val_loss: 0.0104 - val_tp: 785.0000 - val_fp: 128.0000 - val_tn: 206084.0000 - val_fn: 471.0000 - val_accuracy: 0.9971 - val_precision: 0.8598 - val_recall: 0.6250 - val_auc: 0.9568 - val_prc: 0.7773\n",
      "Epoch 32/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0104 - tp: 3015.0000 - fp: 732.0000 - tn: 824368.0000 - fn: 1757.0000 - accuracy: 0.9970 - precision: 0.8046 - recall: 0.6318 - auc: 0.9564 - prc: 0.7563 - val_loss: 0.0104 - val_tp: 777.0000 - val_fp: 145.0000 - val_tn: 206067.0000 - val_fn: 479.0000 - val_accuracy: 0.9970 - val_precision: 0.8427 - val_recall: 0.6186 - val_auc: 0.9429 - val_prc: 0.7749\n",
      "Epoch 33/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0102 - tp: 3053.0000 - fp: 753.0000 - tn: 824347.0000 - fn: 1719.0000 - accuracy: 0.9970 - precision: 0.8022 - recall: 0.6398 - auc: 0.9560 - prc: 0.7582 - val_loss: 0.0104 - val_tp: 747.0000 - val_fp: 122.0000 - val_tn: 206090.0000 - val_fn: 509.0000 - val_accuracy: 0.9970 - val_precision: 0.8596 - val_recall: 0.5947 - val_auc: 0.9491 - val_prc: 0.7779\n",
      "Epoch 34/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0103 - tp: 3035.0000 - fp: 718.0000 - tn: 824382.0000 - fn: 1737.0000 - accuracy: 0.9970 - precision: 0.8087 - recall: 0.6360 - auc: 0.9574 - prc: 0.7606 - val_loss: 0.0103 - val_tp: 778.0000 - val_fp: 146.0000 - val_tn: 206066.0000 - val_fn: 478.0000 - val_accuracy: 0.9970 - val_precision: 0.8420 - val_recall: 0.6194 - val_auc: 0.9486 - val_prc: 0.7789\n",
      "Epoch 35/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0102 - tp: 3039.0000 - fp: 724.0000 - tn: 824376.0000 - fn: 1733.0000 - accuracy: 0.9970 - precision: 0.8076 - recall: 0.6368 - auc: 0.9556 - prc: 0.7599 - val_loss: 0.0102 - val_tp: 781.0000 - val_fp: 128.0000 - val_tn: 206084.0000 - val_fn: 475.0000 - val_accuracy: 0.9971 - val_precision: 0.8592 - val_recall: 0.6218 - val_auc: 0.9574 - val_prc: 0.7815\n",
      "Epoch 36/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0102 - tp: 3027.0000 - fp: 718.0000 - tn: 824382.0000 - fn: 1745.0000 - accuracy: 0.9970 - precision: 0.8083 - recall: 0.6343 - auc: 0.9575 - prc: 0.7607 - val_loss: 0.0102 - val_tp: 772.0000 - val_fp: 138.0000 - val_tn: 206074.0000 - val_fn: 484.0000 - val_accuracy: 0.9970 - val_precision: 0.8484 - val_recall: 0.6146 - val_auc: 0.9565 - val_prc: 0.7808\n",
      "Epoch 37/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0101 - tp: 3048.0000 - fp: 711.0000 - tn: 824389.0000 - fn: 1724.0000 - accuracy: 0.9971 - precision: 0.8109 - recall: 0.6387 - auc: 0.9580 - prc: 0.7635 - val_loss: 0.0100 - val_tp: 786.0000 - val_fp: 135.0000 - val_tn: 206077.0000 - val_fn: 470.0000 - val_accuracy: 0.9971 - val_precision: 0.8534 - val_recall: 0.6258 - val_auc: 0.9579 - val_prc: 0.7847\n",
      "Epoch 38/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0101 - tp: 3007.0000 - fp: 718.0000 - tn: 824382.0000 - fn: 1765.0000 - accuracy: 0.9970 - precision: 0.8072 - recall: 0.6301 - auc: 0.9584 - prc: 0.7633 - val_loss: 0.0099 - val_tp: 817.0000 - val_fp: 162.0000 - val_tn: 206050.0000 - val_fn: 439.0000 - val_accuracy: 0.9971 - val_precision: 0.8345 - val_recall: 0.6505 - val_auc: 0.9597 - val_prc: 0.7837\n",
      "Epoch 39/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0100 - tp: 3067.0000 - fp: 735.0000 - tn: 824365.0000 - fn: 1705.0000 - accuracy: 0.9971 - precision: 0.8067 - recall: 0.6427 - auc: 0.9593 - prc: 0.7664 - val_loss: 0.0101 - val_tp: 748.0000 - val_fp: 119.0000 - val_tn: 206093.0000 - val_fn: 508.0000 - val_accuracy: 0.9970 - val_precision: 0.8627 - val_recall: 0.5955 - val_auc: 0.9516 - val_prc: 0.7821\n",
      "Epoch 40/100\n",
      "406/406 [==============================] - 4s 10ms/step - loss: 0.0101 - tp: 3018.0000 - fp: 724.0000 - tn: 824376.0000 - fn: 1754.0000 - accuracy: 0.9970 - precision: 0.8065 - recall: 0.6324 - auc: 0.9594 - prc: 0.7619 - val_loss: 0.0102 - val_tp: 793.0000 - val_fp: 141.0000 - val_tn: 206071.0000 - val_fn: 463.0000 - val_accuracy: 0.9971 - val_precision: 0.8490 - val_recall: 0.6314 - val_auc: 0.9520 - val_prc: 0.7776\n",
      "Epoch 41/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0100 - tp: 3080.0000 - fp: 738.0000 - tn: 824362.0000 - fn: 1692.0000 - accuracy: 0.9971 - precision: 0.8067 - recall: 0.6454 - auc: 0.9604 - prc: 0.7652 - val_loss: 0.0101 - val_tp: 821.0000 - val_fp: 161.0000 - val_tn: 206051.0000 - val_fn: 435.0000 - val_accuracy: 0.9971 - val_precision: 0.8360 - val_recall: 0.6537 - val_auc: 0.9492 - val_prc: 0.7814\n",
      "Epoch 42/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0101 - tp: 3058.0000 - fp: 749.0000 - tn: 824351.0000 - fn: 1714.0000 - accuracy: 0.9970 - precision: 0.8033 - recall: 0.6408 - auc: 0.9594 - prc: 0.7644 - val_loss: 0.0104 - val_tp: 778.0000 - val_fp: 130.0000 - val_tn: 206082.0000 - val_fn: 478.0000 - val_accuracy: 0.9971 - val_precision: 0.8568 - val_recall: 0.6194 - val_auc: 0.9576 - val_prc: 0.7777\n",
      "Epoch 43/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0099 - tp: 3076.0000 - fp: 714.0000 - tn: 824386.0000 - fn: 1696.0000 - accuracy: 0.9971 - precision: 0.8116 - recall: 0.6446 - auc: 0.9620 - prc: 0.7692 - val_loss: 0.0101 - val_tp: 787.0000 - val_fp: 134.0000 - val_tn: 206078.0000 - val_fn: 469.0000 - val_accuracy: 0.9971 - val_precision: 0.8545 - val_recall: 0.6266 - val_auc: 0.9566 - val_prc: 0.7816\n",
      "Epoch 44/100\n",
      "406/406 [==============================] - 4s 9ms/step - loss: 0.0099 - tp: 3059.0000 - fp: 732.0000 - tn: 824368.0000 - fn: 1713.0000 - accuracy: 0.9971 - precision: 0.8069 - recall: 0.6410 - auc: 0.9610 - prc: 0.7668 - val_loss: 0.0100 - val_tp: 802.0000 - val_fp: 150.0000 - val_tn: 206062.0000 - val_fn: 454.0000 - val_accuracy: 0.9971 - val_precision: 0.8424 - val_recall: 0.6385 - val_auc: 0.9591 - val_prc: 0.7841\n",
      "Epoch 45/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0099 - tp: 3021.0000 - fp: 714.0000 - tn: 824386.0000 - fn: 1751.0000 - accuracy: 0.9970 - precision: 0.8088 - recall: 0.6331 - auc: 0.9632 - prc: 0.7682 - val_loss: 0.0101 - val_tp: 770.0000 - val_fp: 129.0000 - val_tn: 206083.0000 - val_fn: 486.0000 - val_accuracy: 0.9970 - val_precision: 0.8565 - val_recall: 0.6131 - val_auc: 0.9522 - val_prc: 0.7866\n",
      "Epoch 46/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0100 - tp: 3078.0000 - fp: 730.0000 - tn: 824370.0000 - fn: 1694.0000 - accuracy: 0.9971 - precision: 0.8083 - recall: 0.6450 - auc: 0.9619 - prc: 0.7699 - val_loss: 0.0101 - val_tp: 779.0000 - val_fp: 147.0000 - val_tn: 206065.0000 - val_fn: 477.0000 - val_accuracy: 0.9970 - val_precision: 0.8413 - val_recall: 0.6202 - val_auc: 0.9691 - val_prc: 0.7812\n",
      "Epoch 47/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0099 - tp: 3057.0000 - fp: 762.0000 - tn: 824338.0000 - fn: 1715.0000 - accuracy: 0.9970 - precision: 0.8005 - recall: 0.6406 - auc: 0.9613 - prc: 0.7667 - val_loss: 0.0100 - val_tp: 774.0000 - val_fp: 129.0000 - val_tn: 206083.0000 - val_fn: 482.0000 - val_accuracy: 0.9971 - val_precision: 0.8571 - val_recall: 0.6162 - val_auc: 0.9593 - val_prc: 0.7853\n",
      "Epoch 48/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0099 - tp: 3037.0000 - fp: 706.0000 - tn: 824394.0000 - fn: 1735.0000 - accuracy: 0.9971 - precision: 0.8114 - recall: 0.6364 - auc: 0.9616 - prc: 0.7683 - val_loss: 0.0099 - val_tp: 801.0000 - val_fp: 151.0000 - val_tn: 206061.0000 - val_fn: 455.0000 - val_accuracy: 0.9971 - val_precision: 0.8414 - val_recall: 0.6377 - val_auc: 0.9699 - val_prc: 0.7861\n",
      "Epoch 49/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0099 - tp: 3056.0000 - fp: 756.0000 - tn: 824344.0000 - fn: 1716.0000 - accuracy: 0.9970 - precision: 0.8017 - recall: 0.6404 - auc: 0.9636 - prc: 0.7652 - val_loss: 0.0100 - val_tp: 799.0000 - val_fp: 154.0000 - val_tn: 206058.0000 - val_fn: 457.0000 - val_accuracy: 0.9971 - val_precision: 0.8384 - val_recall: 0.6361 - val_auc: 0.9611 - val_prc: 0.7825\n",
      "Epoch 50/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0098 - tp: 3101.0000 - fp: 744.0000 - tn: 824356.0000 - fn: 1671.0000 - accuracy: 0.9971 - precision: 0.8065 - recall: 0.6498 - auc: 0.9635 - prc: 0.7701 - val_loss: 0.0098 - val_tp: 812.0000 - val_fp: 158.0000 - val_tn: 206054.0000 - val_fn: 444.0000 - val_accuracy: 0.9971 - val_precision: 0.8371 - val_recall: 0.6465 - val_auc: 0.9625 - val_prc: 0.7871\n",
      "Epoch 51/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0099 - tp: 3069.0000 - fp: 742.0000 - tn: 824358.0000 - fn: 1703.0000 - accuracy: 0.9971 - precision: 0.8053 - recall: 0.6431 - auc: 0.9633 - prc: 0.7683 - val_loss: 0.0098 - val_tp: 809.0000 - val_fp: 147.0000 - val_tn: 206065.0000 - val_fn: 447.0000 - val_accuracy: 0.9971 - val_precision: 0.8462 - val_recall: 0.6441 - val_auc: 0.9595 - val_prc: 0.7863\n",
      "Epoch 52/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0099 - tp: 3084.0000 - fp: 720.0000 - tn: 824380.0000 - fn: 1688.0000 - accuracy: 0.9971 - precision: 0.8107 - recall: 0.6463 - auc: 0.9622 - prc: 0.7701 - val_loss: 0.0099 - val_tp: 790.0000 - val_fp: 137.0000 - val_tn: 206075.0000 - val_fn: 466.0000 - val_accuracy: 0.9971 - val_precision: 0.8522 - val_recall: 0.6290 - val_auc: 0.9610 - val_prc: 0.7841\n",
      "Epoch 53/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0099 - tp: 3082.0000 - fp: 725.0000 - tn: 824375.0000 - fn: 1690.0000 - accuracy: 0.9971 - precision: 0.8096 - recall: 0.6459 - auc: 0.9630 - prc: 0.7683 - val_loss: 0.0099 - val_tp: 771.0000 - val_fp: 131.0000 - val_tn: 206081.0000 - val_fn: 485.0000 - val_accuracy: 0.9970 - val_precision: 0.8548 - val_recall: 0.6139 - val_auc: 0.9604 - val_prc: 0.7876\n",
      "Epoch 54/100\n",
      "406/406 [==============================] - 4s 10ms/step - loss: 0.0098 - tp: 3115.0000 - fp: 713.0000 - tn: 824387.0000 - fn: 1657.0000 - accuracy: 0.9971 - precision: 0.8137 - recall: 0.6528 - auc: 0.9631 - prc: 0.7718 - val_loss: 0.0098 - val_tp: 811.0000 - val_fp: 158.0000 - val_tn: 206054.0000 - val_fn: 445.0000 - val_accuracy: 0.9971 - val_precision: 0.8369 - val_recall: 0.6457 - val_auc: 0.9672 - val_prc: 0.7875\n",
      "Epoch 55/100\n",
      "406/406 [==============================] - 4s 9ms/step - loss: 0.0098 - tp: 3059.0000 - fp: 724.0000 - tn: 824376.0000 - fn: 1713.0000 - accuracy: 0.9971 - precision: 0.8086 - recall: 0.6410 - auc: 0.9611 - prc: 0.7691 - val_loss: 0.0099 - val_tp: 805.0000 - val_fp: 165.0000 - val_tn: 206047.0000 - val_fn: 451.0000 - val_accuracy: 0.9970 - val_precision: 0.8299 - val_recall: 0.6409 - val_auc: 0.9626 - val_prc: 0.7832\n",
      "Epoch 56/100\n",
      "406/406 [==============================] - 4s 9ms/step - loss: 0.0098 - tp: 3095.0000 - fp: 715.0000 - tn: 824385.0000 - fn: 1677.0000 - accuracy: 0.9971 - precision: 0.8123 - recall: 0.6486 - auc: 0.9639 - prc: 0.7728 - val_loss: 0.0102 - val_tp: 785.0000 - val_fp: 141.0000 - val_tn: 206071.0000 - val_fn: 471.0000 - val_accuracy: 0.9971 - val_precision: 0.8477 - val_recall: 0.6250 - val_auc: 0.9666 - val_prc: 0.7803\n",
      "Epoch 57/100\n",
      "406/406 [==============================] - 4s 9ms/step - loss: 0.0098 - tp: 3082.0000 - fp: 719.0000 - tn: 824381.0000 - fn: 1690.0000 - accuracy: 0.9971 - precision: 0.8108 - recall: 0.6459 - auc: 0.9632 - prc: 0.7716 - val_loss: 0.0098 - val_tp: 812.0000 - val_fp: 163.0000 - val_tn: 206049.0000 - val_fn: 444.0000 - val_accuracy: 0.9971 - val_precision: 0.8328 - val_recall: 0.6465 - val_auc: 0.9649 - val_prc: 0.7860\n",
      "Epoch 58/100\n",
      "406/406 [==============================] - 4s 10ms/step - loss: 0.0098 - tp: 3082.0000 - fp: 733.0000 - tn: 824367.0000 - fn: 1690.0000 - accuracy: 0.9971 - precision: 0.8079 - recall: 0.6459 - auc: 0.9634 - prc: 0.7705 - val_loss: 0.0100 - val_tp: 767.0000 - val_fp: 138.0000 - val_tn: 206074.0000 - val_fn: 489.0000 - val_accuracy: 0.9970 - val_precision: 0.8475 - val_recall: 0.6107 - val_auc: 0.9640 - val_prc: 0.7853\n",
      "Epoch 59/100\n",
      "406/406 [==============================] - 4s 10ms/step - loss: 0.0097 - tp: 3094.0000 - fp: 698.0000 - tn: 824402.0000 - fn: 1678.0000 - accuracy: 0.9971 - precision: 0.8159 - recall: 0.6484 - auc: 0.9640 - prc: 0.7743 - val_loss: 0.0098 - val_tp: 785.0000 - val_fp: 137.0000 - val_tn: 206075.0000 - val_fn: 471.0000 - val_accuracy: 0.9971 - val_precision: 0.8514 - val_recall: 0.6250 - val_auc: 0.9672 - val_prc: 0.7872\n",
      "Epoch 60/100\n",
      "406/406 [==============================] - 4s 10ms/step - loss: 0.0098 - tp: 3069.0000 - fp: 710.0000 - tn: 824390.0000 - fn: 1703.0000 - accuracy: 0.9971 - precision: 0.8121 - recall: 0.6431 - auc: 0.9630 - prc: 0.7727 - val_loss: 0.0099 - val_tp: 815.0000 - val_fp: 158.0000 - val_tn: 206054.0000 - val_fn: 441.0000 - val_accuracy: 0.9971 - val_precision: 0.8376 - val_recall: 0.6489 - val_auc: 0.9679 - val_prc: 0.7857\n",
      "Epoch 61/100\n",
      "406/406 [==============================] - 4s 10ms/step - loss: 0.0098 - tp: 3083.0000 - fp: 712.0000 - tn: 824388.0000 - fn: 1689.0000 - accuracy: 0.9971 - precision: 0.8124 - recall: 0.6461 - auc: 0.9656 - prc: 0.7722 - val_loss: 0.0101 - val_tp: 756.0000 - val_fp: 121.0000 - val_tn: 206091.0000 - val_fn: 500.0000 - val_accuracy: 0.9970 - val_precision: 0.8620 - val_recall: 0.6019 - val_auc: 0.9492 - val_prc: 0.7799\n",
      "Epoch 62/100\n",
      "406/406 [==============================] - 4s 10ms/step - loss: 0.0098 - tp: 3034.0000 - fp: 665.0000 - tn: 824435.0000 - fn: 1738.0000 - accuracy: 0.9971 - precision: 0.8202 - recall: 0.6358 - auc: 0.9628 - prc: 0.7703 - val_loss: 0.0097 - val_tp: 818.0000 - val_fp: 152.0000 - val_tn: 206060.0000 - val_fn: 438.0000 - val_accuracy: 0.9972 - val_precision: 0.8433 - val_recall: 0.6513 - val_auc: 0.9591 - val_prc: 0.7877\n",
      "Epoch 63/100\n",
      "406/406 [==============================] - 4s 10ms/step - loss: 0.0097 - tp: 3090.0000 - fp: 694.0000 - tn: 824406.0000 - fn: 1682.0000 - accuracy: 0.9971 - precision: 0.8166 - recall: 0.6475 - auc: 0.9655 - prc: 0.7730 - val_loss: 0.0099 - val_tp: 830.0000 - val_fp: 176.0000 - val_tn: 206036.0000 - val_fn: 426.0000 - val_accuracy: 0.9971 - val_precision: 0.8250 - val_recall: 0.6608 - val_auc: 0.9721 - val_prc: 0.7852\n",
      "Epoch 64/100\n",
      "406/406 [==============================] - 4s 11ms/step - loss: 0.0097 - tp: 3095.0000 - fp: 718.0000 - tn: 824382.0000 - fn: 1677.0000 - accuracy: 0.9971 - precision: 0.8117 - recall: 0.6486 - auc: 0.9653 - prc: 0.7756 - val_loss: 0.0102 - val_tp: 740.0000 - val_fp: 111.0000 - val_tn: 206101.0000 - val_fn: 516.0000 - val_accuracy: 0.9970 - val_precision: 0.8696 - val_recall: 0.5892 - val_auc: 0.9615 - val_prc: 0.7810\n",
      "Epoch 65/100\n",
      "406/406 [==============================] - 5s 11ms/step - loss: 0.0097 - tp: 3087.0000 - fp: 704.0000 - tn: 824396.0000 - fn: 1685.0000 - accuracy: 0.9971 - precision: 0.8143 - recall: 0.6469 - auc: 0.9639 - prc: 0.7743 - val_loss: 0.0099 - val_tp: 767.0000 - val_fp: 127.0000 - val_tn: 206085.0000 - val_fn: 489.0000 - val_accuracy: 0.9970 - val_precision: 0.8579 - val_recall: 0.6107 - val_auc: 0.9609 - val_prc: 0.7861\n",
      "Epoch 66/100\n",
      "406/406 [==============================] - 4s 10ms/step - loss: 0.0098 - tp: 3106.0000 - fp: 726.0000 - tn: 824374.0000 - fn: 1666.0000 - accuracy: 0.9971 - precision: 0.8105 - recall: 0.6509 - auc: 0.9629 - prc: 0.7706 - val_loss: 0.0097 - val_tp: 802.0000 - val_fp: 156.0000 - val_tn: 206056.0000 - val_fn: 454.0000 - val_accuracy: 0.9971 - val_precision: 0.8372 - val_recall: 0.6385 - val_auc: 0.9798 - val_prc: 0.7896\n",
      "Epoch 67/100\n",
      "406/406 [==============================] - 4s 10ms/step - loss: 0.0096 - tp: 3110.0000 - fp: 711.0000 - tn: 824389.0000 - fn: 1662.0000 - accuracy: 0.9971 - precision: 0.8139 - recall: 0.6517 - auc: 0.9662 - prc: 0.7745 - val_loss: 0.0097 - val_tp: 816.0000 - val_fp: 158.0000 - val_tn: 206054.0000 - val_fn: 440.0000 - val_accuracy: 0.9971 - val_precision: 0.8378 - val_recall: 0.6497 - val_auc: 0.9698 - val_prc: 0.7891\n",
      "Epoch 68/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0096 - tp: 3080.0000 - fp: 707.0000 - tn: 824393.0000 - fn: 1692.0000 - accuracy: 0.9971 - precision: 0.8133 - recall: 0.6454 - auc: 0.9660 - prc: 0.7760 - val_loss: 0.0099 - val_tp: 813.0000 - val_fp: 149.0000 - val_tn: 206063.0000 - val_fn: 443.0000 - val_accuracy: 0.9971 - val_precision: 0.8451 - val_recall: 0.6473 - val_auc: 0.9637 - val_prc: 0.7854\n",
      "Epoch 69/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0096 - tp: 3088.0000 - fp: 708.0000 - tn: 824392.0000 - fn: 1684.0000 - accuracy: 0.9971 - precision: 0.8135 - recall: 0.6471 - auc: 0.9635 - prc: 0.7772 - val_loss: 0.0100 - val_tp: 750.0000 - val_fp: 118.0000 - val_tn: 206094.0000 - val_fn: 506.0000 - val_accuracy: 0.9970 - val_precision: 0.8641 - val_recall: 0.5971 - val_auc: 0.9616 - val_prc: 0.7849\n",
      "Epoch 70/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0097 - tp: 3114.0000 - fp: 739.0000 - tn: 824361.0000 - fn: 1658.0000 - accuracy: 0.9971 - precision: 0.8082 - recall: 0.6526 - auc: 0.9662 - prc: 0.7753 - val_loss: 0.0096 - val_tp: 826.0000 - val_fp: 168.0000 - val_tn: 206044.0000 - val_fn: 430.0000 - val_accuracy: 0.9971 - val_precision: 0.8310 - val_recall: 0.6576 - val_auc: 0.9672 - val_prc: 0.7893\n",
      "Epoch 71/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0096 - tp: 3116.0000 - fp: 714.0000 - tn: 824386.0000 - fn: 1656.0000 - accuracy: 0.9971 - precision: 0.8136 - recall: 0.6530 - auc: 0.9675 - prc: 0.7765 - val_loss: 0.0099 - val_tp: 792.0000 - val_fp: 144.0000 - val_tn: 206068.0000 - val_fn: 464.0000 - val_accuracy: 0.9971 - val_precision: 0.8462 - val_recall: 0.6306 - val_auc: 0.9690 - val_prc: 0.7836\n",
      "Epoch 72/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0096 - tp: 3114.0000 - fp: 701.0000 - tn: 824399.0000 - fn: 1658.0000 - accuracy: 0.9972 - precision: 0.8163 - recall: 0.6526 - auc: 0.9660 - prc: 0.7765 - val_loss: 0.0099 - val_tp: 792.0000 - val_fp: 142.0000 - val_tn: 206070.0000 - val_fn: 464.0000 - val_accuracy: 0.9971 - val_precision: 0.8480 - val_recall: 0.6306 - val_auc: 0.9638 - val_prc: 0.7863\n",
      "Epoch 73/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0095 - tp: 3148.0000 - fp: 723.0000 - tn: 824377.0000 - fn: 1624.0000 - accuracy: 0.9972 - precision: 0.8132 - recall: 0.6597 - auc: 0.9693 - prc: 0.7792 - val_loss: 0.0098 - val_tp: 775.0000 - val_fp: 135.0000 - val_tn: 206077.0000 - val_fn: 481.0000 - val_accuracy: 0.9970 - val_precision: 0.8516 - val_recall: 0.6170 - val_auc: 0.9717 - val_prc: 0.7874\n",
      "Epoch 74/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0096 - tp: 3102.0000 - fp: 701.0000 - tn: 824399.0000 - fn: 1670.0000 - accuracy: 0.9971 - precision: 0.8157 - recall: 0.6500 - auc: 0.9660 - prc: 0.7789 - val_loss: 0.0096 - val_tp: 802.0000 - val_fp: 144.0000 - val_tn: 206068.0000 - val_fn: 454.0000 - val_accuracy: 0.9971 - val_precision: 0.8478 - val_recall: 0.6385 - val_auc: 0.9747 - val_prc: 0.7917\n",
      "Epoch 75/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0096 - tp: 3095.0000 - fp: 696.0000 - tn: 824404.0000 - fn: 1677.0000 - accuracy: 0.9971 - precision: 0.8164 - recall: 0.6486 - auc: 0.9688 - prc: 0.7779 - val_loss: 0.0098 - val_tp: 785.0000 - val_fp: 145.0000 - val_tn: 206067.0000 - val_fn: 471.0000 - val_accuracy: 0.9970 - val_precision: 0.8441 - val_recall: 0.6250 - val_auc: 0.9668 - val_prc: 0.7862\n",
      "Epoch 76/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0096 - tp: 3087.0000 - fp: 715.0000 - tn: 824385.0000 - fn: 1685.0000 - accuracy: 0.9971 - precision: 0.8119 - recall: 0.6469 - auc: 0.9672 - prc: 0.7771 - val_loss: 0.0097 - val_tp: 788.0000 - val_fp: 142.0000 - val_tn: 206070.0000 - val_fn: 468.0000 - val_accuracy: 0.9971 - val_precision: 0.8473 - val_recall: 0.6274 - val_auc: 0.9623 - val_prc: 0.7880\n",
      "Epoch 77/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0096 - tp: 3088.0000 - fp: 693.0000 - tn: 824407.0000 - fn: 1684.0000 - accuracy: 0.9971 - precision: 0.8167 - recall: 0.6471 - auc: 0.9654 - prc: 0.7769 - val_loss: 0.0099 - val_tp: 771.0000 - val_fp: 138.0000 - val_tn: 206074.0000 - val_fn: 485.0000 - val_accuracy: 0.9970 - val_precision: 0.8482 - val_recall: 0.6139 - val_auc: 0.9572 - val_prc: 0.7874\n",
      "Epoch 78/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0095 - tp: 3112.0000 - fp: 708.0000 - tn: 824392.0000 - fn: 1660.0000 - accuracy: 0.9971 - precision: 0.8147 - recall: 0.6521 - auc: 0.9680 - prc: 0.7792 - val_loss: 0.0103 - val_tp: 779.0000 - val_fp: 137.0000 - val_tn: 206075.0000 - val_fn: 477.0000 - val_accuracy: 0.9970 - val_precision: 0.8504 - val_recall: 0.6202 - val_auc: 0.9511 - val_prc: 0.7804\n",
      "Epoch 79/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0096 - tp: 3129.0000 - fp: 687.0000 - tn: 824413.0000 - fn: 1643.0000 - accuracy: 0.9972 - precision: 0.8200 - recall: 0.6557 - auc: 0.9658 - prc: 0.7797 - val_loss: 0.0099 - val_tp: 797.0000 - val_fp: 155.0000 - val_tn: 206057.0000 - val_fn: 459.0000 - val_accuracy: 0.9970 - val_precision: 0.8372 - val_recall: 0.6346 - val_auc: 0.9621 - val_prc: 0.7861\n",
      "Epoch 80/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0095 - tp: 3054.0000 - fp: 688.0000 - tn: 824412.0000 - fn: 1718.0000 - accuracy: 0.9971 - precision: 0.8161 - recall: 0.6400 - auc: 0.9677 - prc: 0.7775 - val_loss: 0.0098 - val_tp: 754.0000 - val_fp: 125.0000 - val_tn: 206087.0000 - val_fn: 502.0000 - val_accuracy: 0.9970 - val_precision: 0.8578 - val_recall: 0.6003 - val_auc: 0.9621 - val_prc: 0.7886\n",
      "Epoch 81/100\n",
      "406/406 [==============================] - 3s 7ms/step - loss: 0.0096 - tp: 3082.0000 - fp: 712.0000 - tn: 824388.0000 - fn: 1690.0000 - accuracy: 0.9971 - precision: 0.8123 - recall: 0.6459 - auc: 0.9658 - prc: 0.7758 - val_loss: 0.0099 - val_tp: 760.0000 - val_fp: 127.0000 - val_tn: 206085.0000 - val_fn: 496.0000 - val_accuracy: 0.9970 - val_precision: 0.8568 - val_recall: 0.6051 - val_auc: 0.9617 - val_prc: 0.7863\n",
      "Epoch 82/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0095 - tp: 3064.0000 - fp: 679.0000 - tn: 824421.0000 - fn: 1708.0000 - accuracy: 0.9971 - precision: 0.8186 - recall: 0.6421 - auc: 0.9685 - prc: 0.7803 - val_loss: 0.0098 - val_tp: 791.0000 - val_fp: 150.0000 - val_tn: 206062.0000 - val_fn: 465.0000 - val_accuracy: 0.9970 - val_precision: 0.8406 - val_recall: 0.6298 - val_auc: 0.9672 - val_prc: 0.7852\n",
      "Epoch 83/100\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0095 - tp: 3100.0000 - fp: 711.0000 - tn: 824389.0000 - fn: 1672.0000 - accuracy: 0.9971 - precision: 0.8134 - recall: 0.6496 - auc: 0.9663 - prc: 0.7807 - val_loss: 0.0098 - val_tp: 775.0000 - val_fp: 136.0000 - val_tn: 206076.0000 - val_fn: 481.0000 - val_accuracy: 0.9970 - val_precision: 0.8507 - val_recall: 0.6170 - val_auc: 0.9693 - val_prc: 0.7874\n",
      "Epoch 84/100\n",
      "401/406 [============================>.] - ETA: 0s - loss: 0.0095 - tp: 3054.0000 - fp: 700.0000 - tn: 815820.0000 - fn: 1674.0000 - accuracy: 0.9971 - precision: 0.8135 - recall: 0.6459 - auc: 0.9677 - prc: 0.7784Restoring model weights from the end of the best epoch: 74.\n",
      "406/406 [==============================] - 3s 8ms/step - loss: 0.0095 - tp: 3083.0000 - fp: 707.0000 - tn: 824393.0000 - fn: 1689.0000 - accuracy: 0.9971 - precision: 0.8135 - recall: 0.6461 - auc: 0.9674 - prc: 0.7784 - val_loss: 0.0098 - val_tp: 763.0000 - val_fp: 124.0000 - val_tn: 206088.0000 - val_fn: 493.0000 - val_accuracy: 0.9970 - val_precision: 0.8602 - val_recall: 0.6075 - val_auc: 0.9701 - val_prc: 0.7880\n",
      "Epoch 84: early stopping\n"
     ]
    }
   ],
   "source": [
    "baseline_history = model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=(val_features, val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406/406 [==============================] - 1s 2ms/step\n",
      "127/127 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "train_predictions_baseline = model.predict(train_features, batch_size=BATCH_SIZE)\n",
    "test_predictions_baseline = model.predict(test_features, batch_size=BATCH_SIZE)\n",
    "baseline_results = model.evaluate(test_features, test_labels,batch_size=BATCH_SIZE, verbose=0)\n",
    "results = model.evaluate(train_features, train_labels, batch_size=BATCH_SIZE, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('Model')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d722d3adfa415172c1f5238b519fb86b488acdae450fd691ab06c09f4ca9173"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml3950')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
